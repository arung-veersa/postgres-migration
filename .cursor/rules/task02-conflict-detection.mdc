---
description: Task 02 - conflict detection v3 architecture, execution flow, and ECS container implementation
globs: Scripts12/**/*.py, Scripts12/**/*.sql, Scripts12/**/*.json, Scripts13/**/*.py, Scripts13/**/*.sql, Scripts13/**/*.json
alwaysApply: false
---

# Task 02 Conflict Detection (v3) -- Scripts12 (Lambda) / Scripts13 (ECS)

## Databases

- **Snowflake (read-only source)**: `ANALYTICS.BI.FACTVISITCALLPERFORMANCE_CR` view with dimension joins. RSA key auth, streaming cursor. Temp tables require `database` and `schema` on connection.
- **PostgreSQL (read/write target)**: `conflict_management.conflict_dev` schema. Tables: `conflicts` (parent), `conflictvisitmaps` (detail with 7 conflict flags). psycopg2 driver. All column names double-quoted (case-sensitive).

## Key Files (under Scripts13/tasks/)

- `scripts/main.py` -- ECS container entry point, ACTION dispatching, SIGTERM handling
- `scripts/actions/task00_preflight.py` -- Task 00: pre-run validation, pg_cron disable, InProgressFlag
- `scripts/actions/task01_copy_to_staging.py` -- Task 01: PPR sync from Snowflake dims, staging populate
- `scripts/actions/task02_00_conflict_update.py` -- Task 02.00: v3 conflict detection UPDATE pipeline
- `scripts/actions/task99_postflight.py` -- Task 99: VACUUM/ANALYZE, pg_cron re-enable, email, log summary
- `scripts/actions/validate_config.py` -- Standalone config validation
- `scripts/actions/test_connections.py` -- Standalone connectivity test
- `lib/conflict_processor.py` -- Core logic: v3 streaming, batch updates, stale cleanup
- `lib/query_builder.py` -- Builds Snowflake SQL from v3 templates
- `lib/connections.py` -- Snowflake and PostgreSQL connection managers
- `lib/utils.py` -- Logging, formatting, memory estimation utilities
- `lib/email_sender.py` -- AWS SES HTML email sender for pipeline status reports
- `config/config.json` -- Runtime config (lookback_hours=36, batch_size=5000, pipeline, email, env var substitution)
- `config/settings.py` -- Config loader with JSON-safe env var substitution
- `sql/sf_task01_dim_payer_provider.sql` -- Task 01: Snowflake payer-provider dimension query
- `sql/sf_task02_v3_step*.sql` -- Snowflake SQL templates for steps 1/2/3
- `Dockerfile` -- Container image definition (python:3.11-slim)
- `deploy/build-and-push-ecr.ps1` -- Interactive deploy script (SSO, build, push, register task def, run)
- `deploy/ecs-task-definition.json` -- ECS Fargate task definition template (placeholders resolved from .env)
- `deploy/.env.example` -- Template for deploy/.env with all required secret/config keys
- `tests/test_comprehensive.py` -- 81 pytest tests
- `tests/sql/sf_task02_v3-*-defaults.sql` -- Standalone test queries for manual Snowflake testing

## v3 Execution Flow

1. **Step 0**: Load excluded SSNs into Snowflake temp table (`excluded_ssns_temp`)
2. **Step 1**: Create `delta_keys` temp table (DISTINCT VisitDate, SSN from recent updates)
3. **Step 2 Part A**: Create `base_visits` with delta rows only (`is_delta=1`)
4. **Step 2 Part B** (asymmetric): INSERT related non-delta rows via `INNER JOIN delta_keys` (`is_delta=0`)
5. **Step 2d**: Stream `(visit_date, ssn)` pairs from `delta_keys` to PostgreSQL `_tmp_delta_pairs` via chunked COPY
6. **Step 3**: Self-join `base_visits` with `V1.is_delta=1` constraint (asymmetric), stream conflicts
7. **Step 4**: Pair-precise stale cleanup -- Phase 1: identify stale via anti-join on `_tmp_delta_pairs`; Phase 2: batched UPDATE (100K chunks), `StatusFlag='R'`

## Critical Design Decisions

- **Two-part base_visits (CREATE + INSERT, not UNION ALL)**: Same SQL template formatted twice with different placeholders. Two separate statements give per-leg timing in logs and avoid the `OR + IN` subquery that prevented Snowflake partition pruning. Both parts share 120 columns + 11 dimension JOINs -- duplication is unavoidable since Step 3 needs resolved columns.
- **`is_delta` flag**: Constrains self-join to Delta-vs-All (not All-vs-All on 9.6M rows)
- **Streaming cursor + batch processing**: Step 3 results streamed from Snowflake (not fetched all at once). Batches of 5,000 rows: fetch existing PG records, detect changes (7 flags + 40 columns), UPDATE dirty rows only, commit per batch. Single-threaded by design (bottleneck is Snowflake query time, not Python processing).
- **Pair-precise stale cleanup**: Uses exact `(VisitDate, SSN)` pairs streamed via chunked COPY (100K/chunk), NOT separate DISTINCT lists (cross-product caused 3.9M false stale positives)
- **UUID type matching**: `_tmp_seen_conflicts` uses UUID columns to match `conflictvisitmaps` indexes
- **Conflict flag simplification**: 7 rules omit redundant `ProviderID != ConProviderID` (enforced by JOIN). Direct column `=` comparison instead of CONCAT-based string ops.
- **StatusFlag values**: 'N'=New/Active, 'U'=Updated (set on re-detection), 'R'=Resolved/Stale, 'W'=Whitelisted, 'I'=Ignored (W and I never overwritten)

## Stats Fields (backward compat aliases)

- `delta_keys_count` -> alias for `delta_pairs_count`
- `modified_visit_ids_count` -> alias for `delta_ssns_count`
- `stale_conflicts_reset` -> alias for `stale_conflicts_resolved`

## Code Cleanup Notes

- v2 methods removed: `stream_and_process_conflicts()`, `build_conflict_detection_query()`, `_build_symmetric_conflict_pairs()`, `_build_asymmetric_conflict_pairs()`, `execute_batch_update()`, `fetch_reference_data()`
- v1/v2 SQL template and default files deleted (no longer referenced by any code)
- `delta_keys` (step1) is always created in both modes (needed for stale cleanup scoping, not just asymmetric join)

## Latest Performance Run (2026-02-10, asymmetric + stale cleanup)

| Metric | Value |
|---|---|
| Total time | 8m 29s (509s) |
| Rows fetched from Snowflake | 153,901 |
| Matched in Postgres | 51,612 (33.5%) |
| New conflicts (not in PG) | 102,289 (66.5%) |
| Changes detected | 6,134 (5,202 flag + 932 business) |
| Rows actually updated | 216 |
| Rows skipped (no changes) | 45,478 (88.1%) |
| Stale conflicts resolved | 9,294 → StatusFlag='R' |
| Delta pairs (stale scope) | 12,517,521 (640K SSNs × 596 dates) |
| Peak memory | 455 MB of 5,120 MB allocated |
| Errors | 0 |

### Time breakdown:
- Step 0 (excluded SSNs): ~6s
- Step 1 (delta_keys): ~5s
- Step 2 (base_visits A+B): ~148s
- Step 2d (delta pairs → PG): ~92s
- Step 3 (conflict detection + streaming batches): ~140s
- Step 4 (stale cleanup): ~117s (84s identify + 32s update)

## Current State (as of 2026-02-12)

### Scripts12 (Lambda) -- FROZEN
- Asymmetric join + pair-precise stale cleanup: WORKING
- UPDATE logic with conditional flags and change detection: WORKING
- 81 pytest tests passing
- No further development planned here

### Scripts13 (ECS) -- ACTIVE DEVELOPMENT
- **ECS containerization COMPLETE**: Dockerfile, task definition, ECR deployment, interactive deploy script
- Entry point: `scripts/main.py` with comma-separated ACTION env var and DEFAULT_ACTIONS pipeline
- JSON-safe env var substitution in `settings.py` (handles RSA keys with newlines)
- Graceful SIGTERM shutdown handling
- **Modular action architecture**: main.py is a lean orchestrator; each action in `scripts/actions/<key>.py`
- **task01_copy_to_staging COMPLETE**: PPR sync via temp-table + UPDATE FROM JOIN (~3s), staging populate (~280s for 8M rows)
- **Pipeline summary logging**: Plain-text summary always logged to CloudWatch (independent of email)
- Successfully deployed and tested on ECS Fargate (~14 min full pipeline with task01)
- INSERT logic for new conflicts (~102K detected but not inserted): NOT YET IMPLEMENTED
- Conflicts table aggregation: NOT YET IMPLEMENTED
- UpdateFlag cleanup: DEFERRED
- AWS Secrets Manager integration: NOT YET IMPLEMENTED (using plain env vars)

## Scripts13 ECS Architecture Notes

### Container Entry Point (`scripts/main.py`)
- `ACTION=""` (default): runs full pipeline `task00_preflight -> task01_copy_to_staging -> task02_00_conflict_update -> task99_postflight`
- `ACTION="test_connections"`: runs single action
- `ACTION="validate_config,test_connections"`: comma-separated sequential execution
- SIGTERM handler for graceful ECS shutdown (30s stop timeout)
- All parameters from env vars with config.json defaults as fallback
- **Postflight runs even on failure** (re-enables pg_cron, clears InProgressFlag)

### Action Naming Convention
- File: `<registry_key>.py` (e.g. `task01_copy_to_staging.py`)
- Function: `run_<registry_key>()` (e.g. `run_task01_copy_to_staging()`)
- Import: `from scripts.actions.<key> import run_<key>`

### Pipeline Actions (DEFAULT_ACTIONS)
- `task00_preflight`: 1) Validate config params, 2) Verify Snowflake+PG connectivity, 3) Check required tables, 4) Disable pg_cron job, 5) Set InProgressFlag=1, 6) Capture pre-run row counts
- `task01_copy_to_staging`: 1) Sync payer_provider_reminders from Snowflake dims (temp-table + UPDATE FROM JOIN), 2) Truncate+populate conflictlog_staging from conflictvisitmaps+conflicts (date-filtered)
- `task02_00_conflict_update`: v3 conflict detection UPDATE pipeline (streaming cursor, batch processing, stale cleanup)
- `task99_postflight`: 1) VACUUM all tables, 2) ANALYZE all tables, 3) Set InProgressFlag=0, 4) Refresh materialized view (CONCURRENTLY), 5) Re-enable pg_cron job, 6) Capture post-run row counts, 7) Log pipeline summary, 8) Send SES email (if enabled)

### Standalone Actions (not in default pipeline, available via ACTION env var)
- `validate_config`: Print and validate config summary (included in preflight)
- `test_connections`: Test Snowflake and PostgreSQL connectivity (included in preflight)

### Key Design: Preflight/Postflight
- Config validation runs first (before any DB connections) to fail fast
- pg_cron commands connect to `postgres` database (not `conflict_management`)
- VACUUM/ANALYZE require `autocommit=True` on psycopg2 connections
- VACUUM/ANALYZE and InProgressFlag=0 run before MV refresh and pg_cron re-enable (cleanup first, then restore)
- Postflight runs even on pipeline failure (re-enables pg_cron, clears InProgressFlag)
- Postflight receives all prior action results via `_pipeline_results` module-level list
- Email via `boto3` SES with HTML template matching Snowflake SEND_TASK_STATUS_EMAIL format
- `config.json` has `pipeline` section (pg_cron job name, materialized view, required tables) and `email` section (enabled, region, sender, recipients)

### Deployment
- `deploy/build-and-push-ecr.ps1`: Interactive PowerShell script with 5 steps (each has a default, Enter to accept):
  1. SSO login [default: No]
  2. Docker build [default: Yes]
  3. ECR push [default: Yes if built, No if skipped]
  4. Register task definition [default: No -- only needed when env vars or CPU/memory change]
  5. ECS run-task (action selection menu, default: Skip)
- `deploy/ecs-task-definition.json`: Template with `<ACCOUNT_ID>`, `<REGION>`, `<CPU>`, `<MEMORY>`, `<YOUR_*>` placeholders
- CPU/memory configurable via `$Cpu` / `$Memory` in the script's CONFIGURATION section
- `deploy/.env`: Secret values for template resolution (gitignored). Copy from `deploy/.env.example`.
- `deploy/.env.example`: Template .env with placeholder values for onboarding
- `deploy/.generated-taskdef.json`: Resolved task definition output (gitignored, written by script)
- `deploy/ecs-task-definition.dev.json`: Manually-maintained dev reference copy (gitignored)
- CloudWatch log group `/ecs/task02-conflict-updater` must be created manually before first run

### What stays the same from Scripts12:
- All Python code in `lib/` (conflict_processor, query_builder, connections, utils)
- SQL templates in `sql/`
- Snowflake and PostgreSQL connection logic
- v3 execution flow (Steps 0-4)
- Test suite in `tests/`
